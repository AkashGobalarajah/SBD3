---
title: "Group 4 - Disneyland Text Mining"
author: "Akash Gobalarajah, Cyril Alain Scheurmann, Keijo Alexander Nierula, Roman Krass"
date: "2024.03.14"
output:
html_document:
toc: true
toc_depth: 2
toc_float: true
number_sections: true
---

```{r setup, include=FALSE}
# Getting started by changing the default output of echo to TRUE for the current document
knitr::opts_chunk$set(echo = TRUE, cache=TRUE)

# Create a list of packages to install and load into the work space
libraries = c("tm", "SnowballC", "wordcloud", "RColorBrewer", "syuzhet", "cld2", "topicmodels", "quanteda", "tidyverse", "tidytext", "reshape2")

# Install packages from the predefined libraries list
lapply(libraries, function(x) if (!(x %in% installed.packages())) {
  install.packages(x)
})


# Load libraries
lapply(libraries, library, quietly = TRUE, character.only = TRUE)

# Remove current environment
rm(list=ls())

#scientific notation: off
options(scipen=999)

# TEST 
```

```{r, echo=FALSE}
# Load the data
load("/Users/keijo/Documents/FH/Sem6/SBD3/git/SBD3/Homework2/Disneyland.rda")

# Check the structure of the data
str(reviews)

head(reviews)

# How many review_locations:
table(reviews$Reviewer_Location)
```


# 1. What can you tell us about the customers that write reviews? 

* We know that the customers are from all over the world. The most reviews are from the United States, followed by the United Kingdom and Australia. 


# 2. What do the visitors talk about in their reviews and how does it relate to sentiment/ratings? 


## Pre-prosessing the data
```{r}
# Are there other languages than english?
languages <- detect_language(reviews$Review_Text)
table(languages)

nrow(reviews)
# Filter the reviews to only include english reviews
reviews <- reviews[languages == "en", ]

# Check if there are duplicate reviews
duplicate_rows <- duplicated(reviews)

# It seems we have 12 duplicates
print(sum(duplicate_rows))

# Removing the duplicates
reviews <- unique(reviews)


# Check if there are any missing values
missing_values <- colSums(is.na(reviews))
print(missing_values)

# Remove the reviews missing values (year and year_month are missing 2613 times)
reviews <- reviews[complete.cases(reviews), ]
```

After pre-processing the dataset we can now start the Topic Modelling:

```{r}
# Tokenize the reviews
tokens <- tokens(reviews$Review_Text,
                 remove_punct = TRUE,
                 remove_symbols = TRUE,
                 remove_numbers = TRUE,
                 remove_url = TRUE,
                 remove_separators = TRUE)
extended_stopwords <- c(stopwords("english"), "disney", "disneyland", "park", "time", "day", "get", "go")

# Remove common stopwords
tokens <- tokens_select(tokens, pattern = extended_stopwords, selection = "remove")

# transform to lowercase
tokens <- tokens_tolower(tokens)

# Stem all words
tokens <-tokens_wordstem(tokens)

# Create n-grams of any length
tokens <- tokens_ngrams(tokens, n = 1:2)

# Create Document-feature-matrix
matrix <-dfm(tokens)

# Create LDA model
reviews_lda <- LDA(matrix, k = 3, control = list(seed = 1111))

reviews_lda_td <- tidy(reviews_lda)
reviews_lda_td

# Extract top-terms per topic
top_terms <- reviews_lda_td %>%
  group_by(topic) %>%
  top_n(8, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)


top_terms %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip()
```


```{r}

# First we reate a word cloud to visualize the most common words in the reviews
reviews_corpus <- Corpus(VectorSource(reviews$Review_Text))

# Preprocessing the text data:
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
reviews_corpus <- tm_map(reviews_corpus, toSpace, "/")
reviews_corpus <- tm_map(reviews_corpus, toSpace, "@")
reviews_corpus <- tm_map(reviews_corpus, toSpace, "\\|")
reviews_corpus <- tm_map(reviews_corpus, content_transformer(tolower))
reviews_corpus <- tm_map(reviews_corpus, removeNumbers)
reviews_corpus <- tm_map(reviews_corpus, removeWords, c("disney", "park", "disneyland", stopwords("english")))
reviews_corpus <- tm_map(reviews_corpus, removePunctuation)
reviews_corpus <- tm_map(reviews_corpus, stripWhitespace)

# # Creating a term document matrix
# term.matrix <- TermDocumentMatrix(reviews_corpus)
# 
# # Remove terms that occur in less than 1% of the documents - because the dataset was too large to process (R ran out of memory)
# term.matrix <- removeSparseTerms(term.matrix, 0.99)
# 
# # convert to a regular matrix
# term.matrix <- as.matrix(term.matrix)
# 
# v <- sort(rowSums(term.matrix),decreasing=TRUE)
# data <- data.frame(word = names(v),freq=v)
# head(data, 10)
# 
# set.seed(17)
# wordcloud(words = data$word, freq = data$freq, min.freq = 1,
#           max.words=200, random.order=FALSE, rot.per=0.35,
#           colors=brewer.pal(8, "Dark2"))


```

```{r}
#Now we create a wordcloud for bad sentiment reviews

# Select only the reviews with a rating of 1 or 2
reviews_corpus_negative <- reviews_corpus[reviews$Rating %in% c(1, 2)]

reviews_corpus_negative$sentiment.syuzhet <- get_sentiment(reviews_corpus_negative,
                                                  method="syuzhet",
                                                  lang="english")

# Create a word cloud for the review with a negative sentiment
reviews_corpus_negative <- reviews_corpus[reviews_corpus$sentiment.syuzhet < 0]

# Creating a term document matrix
term.matrix.negative <- TermDocumentMatrix(reviews_corpus_negative)
term.matrix.negative <- as.matrix(term.matrix.negative)

v <- sort(rowSums(term.matrix.negative),decreasing=TRUE)
data <- data.frame(word = names(v),freq=v)

set.seed(17)
wordcloud(words = data$word, freq = data$freq, min.freq = 1,
          max.words=200, random.order=FALSE, rot.per=0.35,
          colors=brewer.pal(8, "Dark2"))


```

Wordcloud for positive sentiment reviews

```{r}
# Select only the reviews with a rating of 4 or 5
reviews_corpus_positive <- reviews_corpus[reviews$Rating %in% c(4, 5)]

reviews_corpus_positive$sentiment.syuzhet <- get_sentiment(reviews_corpus_positive,
                                                  method="syuzhet",
                                                  lang="english")



# Create a word cloud for the review with a positive sentiment
# reviews_corpus_positive_data <- reviews_corpus_positive[reviews_corpus_positive$sentiment.syuzhet > 0]

# Creating a term document matrix
term.matrix.positive <- TermDocumentMatrix(reviews_corpus_positive)
term.matrix.positive <- as.matrix(term.matrix.positive)

v <- sort(rowSums(term.matrix.positive),decreasing=TRUE)

data <- data.frame(word = names(v),freq=v)

data <- data[data$freq > 0, ]

set.seed(17)
wordcloud(words = data$word, freq = data$freq, min.freq = 1,
          max.words=200, random.order=FALSE, rot.per=0.35,
          colors=brewer.pal(8, "Dark2"))



```

```{r}
# Other example

reviews$dic1 <- "NA"
reviews$dic1 <-str_count(reviews$reviewText, "design|color|black|looks") #is this a good dictonary?!
reviews$dic1_occurence<- "NA"
#select threshold for occurence of the topic
reviews$dic1_occurence<-ifelse(reviews$dic1>=2,1,0)
#number of reviews that cover topic
sum(reviews$dic1_occurence)

## VISUALIZE RESULTS
#sum of reviews that cover topic per day
plot_data <- reviews %>%
  group_by (reviewDate_month) %>%
  summarise(n=sum(dic1_occurence))

ggplot (plot_data, aes (x=reviewDate_month, y=n)) + geom_bar(stat = "identity")+ theme_minimal() + ggtitle("Number of reviews covering the topic (per month)")

### - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
### STEP 4: PERFORM SENTIMENT ANALYSIS
### - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

#Select text column and calculate sentiment scores. You can change the method (e.g."syuzhet", "bing", "nrc")
reviews$sentiment <- "NA"
reviews$sentiment <- get_sentiment(reviews$reviewText, method="syuzhet", lang="english")

## VISUALIZE RESULTS
# mean over time
plot_data <- reviews %>%
  group_by (reviewDate_month) %>%
  summarise(n=mean(sentiment))

ggplot(plot_data, aes (x=reviewDate_month, y=n)) + geom_line()+ theme_minimal() + ggtitle("Sentiment scores over time (mean per month)")


```

# 3. What differences can you detect for the three different locations and are there any interesting trends over time? 

```{r}
# Plot the ratings for several locations over time



```


# 4. What specific advice can you give to our park management based on your analysis? How can we integrate the analysis of reviews in our internal processes, can you think of any data products that would be of value for us?

```{r}

```
